# llamaindex-rag-chatbot-internship
RAG-based chatbot developed during internship at Wexdi Software Solutions using LlamaIndex, FAISS, and LLMs like GPT/Llama 2 for document-aware conversations.

# ğŸ¤– RAG-Based Chatbot using LlamaIndex

This project was developed as part of my internship at **Wexdi Software Solutions**.  
It focuses on building a chatbot that uses **Retrieval-Augmented Generation (RAG)** architecture with **LlamaIndex** and **Large Language Models (LLMs)** to generate context-aware responses from documents.

---

## ğŸ¯ Objective
To create an intelligent chatbot that can fetch relevant information from indexed documents and generate accurate responses using an LLM such as GPT or Llama 2.

---

## ğŸš€ Key Features
- ğŸ“„ **Document Processing**: Parses and indexes various formats like PDF, Word, and text files.
- ğŸ” **Semantic Search**: Uses FAISS or ChromaDB for fast and relevant document retrieval.
- ğŸ§  **LLM Integration**: Generates natural language responses using models like GPT, Llama 2, or Claude.
- ğŸ’¬ **Chat Interface**: Built with Flask or Streamlit for a user-friendly experience.
- ğŸ—ƒï¸ **Memory & Logging**: Tracks user queries and chatbot responses for improved interaction.

---

## ğŸ› ï¸ Tech Stack
- **Backend**: Python, FastAPI / Flask  
- **Frontend**: Streamlit / HTML-CSS (optional)  
- **LLM**: GPT, Llama 2, or Claude  
- **Indexing**: LlamaIndex  
- **Vector Store**: FAISS, Pinecone, or ChromaDB  
- **Database**: PostgreSQL or MongoDB

  ## ğŸ“„ Documentation
Please refer to the detailed project document:  
ğŸ‘‰ [`rag-based-chatbot.pdf`](rag-based-chatbot.pdf)

---

## ğŸ“Œ Note
This repository showcases the architecture and planning of the chatbot project. Source code is not included here due to confidentiality/internship limitations.
